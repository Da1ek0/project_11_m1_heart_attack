from fastapi import FastAPI, UploadFile, File, HTTPException
import pandas as pd
import joblib
from io import BytesIO
import numpy as np
from fastapi.responses import JSONResponse, HTMLResponse
import re

app = FastAPI(title="Heart Attack Prediction API"
              description="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ —Å–µ—Ä–¥–µ—á–Ω–æ–≥–æ –ø—Ä–∏—Å—Ç—É–ø–∞",
              version="1.0",
    contact={
        "name": "Alexandr Sorokin",
        "email": "as1983@yandex.ru"
    })

try:
    model = joblib.load("model.pkl")
    print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    if hasattr(model, 'feature_names_in_'):
        EXPECTED_FEATURES = model.feature_names_in_.tolist()
        print(f"üìã –û–∂–∏–¥–∞–µ–º—ã–µ —Ñ–∏—á–∏: {EXPECTED_FEATURES}")
    else:
        EXPECTED_FEATURES = [
            'age', 'cholesterol', 'heart_rate', 'diabetes', 'family_history', 'smoking', 
            'obesity', 'alcohol_consumption', 'exercise_hours_per_week', 'diet', 
            'previous_heart_problems', 'medication_use', 'stress_level', 'sedentary_hours_per_day', 
            'income', 'bmi', 'triglycerides', 'physical_activity_days_per_week', 'sleep_hours_per_day', 
            'blood_sugar', 'ckmb', 'troponin', 'gender', 'systolic_blood_pressure', 'diastolic_blood_pressure'
        ]
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    model = None
    EXPECTED_FEATURES = []

threshold = 0.3

@app.get("/", response_class=HTMLResponse)
async def home():
    return """
    <html>
        <head>
            <title>Heart Attack Risk Prediction</title>
        </head>
        <body>
            <h1>–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–∏—Å–∫–∞ —Å–µ—Ä–¥–µ—á–Ω–æ–≥–æ –ø—Ä–∏—Å—Ç—É–ø–∞</h1>
            <p>–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —á–µ—Ä–µ–∑ <a href="/docs">Swagger UI</a></p>
            <p>–ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ POST –∑–∞–ø—Ä–æ—Å –Ω–∞ /predict/ —Å —Ñ–∞–π–ª–æ–º</p>
        </body>
    </html>
    """

def to_snake_case(column_name: str) -> str:
    snake_name = re.sub(r'[\s\-\.\(\)\/]+', '_', column_name)
    snake_name = re.sub(r'[^a-zA-Z0-9_]', '', snake_name)
    snake_name = snake_name.lower()
    snake_name = re.sub(r'_+', '_', snake_name)
    snake_name = snake_name.strip('_')
    return snake_name

def normalize_dataframe_columns(df: pd.DataFrame) -> pd.DataFrame:
    df_normalized = df.copy()
    new_columns = [to_snake_case(col) for col in df_normalized.columns]
    df_normalized.columns = new_columns
    return df_normalized

def fix_gender_column(df):
    if 'gender' in df.columns:
        print(f"üîß –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ gender. –ò—Å—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {df['gender'].unique()}")
        
        df['gender'] = df['gender'].astype(str).str.strip().str.lower()
        
        gender_mapping = {
            '1': 1, '1.0': 1, 'male': 1, '–º': 1, 'm': 1, '–º—É–∂—Å–∫–æ–π': 1,
            '0': 0, '0.0': 0, 'female': 0, '–∂': 0, 'f': 0, '–∂–µ–Ω—Å–∫–∏–π': 0
        }
        
        df['gender'] = df['gender'].map(gender_mapping)
        df['gender'] = df['gender'].fillna(0)
        df['gender'] = df['gender'].astype(int)
        
        print(f"üîß Gender –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: {df['gender'].unique()}")
    
    return df

def convert_numpy_types(obj):
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç numpy —Ç–∏–ø—ã –≤ native Python —Ç–∏–ø—ã –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    """
    if isinstance(obj, (np.integer, np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32)):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_numpy_types(item) for item in obj)
    else:
        return obj

@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    if not file.filename.endswith('.csv'):
        raise HTTPException(status_code=400, detail="–¢–æ–ª—å–∫–æ CSV —Ñ–∞–π–ª—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è")
    
    if model is None:
        raise HTTPException(status_code=500, detail="–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        contents = await file.read()
        df = pd.read_csv(BytesIO(contents))
        
        print(f"üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ ID –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if 'id' in df.columns:
            ids = df['id'].tolist()
        else:
            ids = [i+1 for i in range(len(df))]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
        df_normalized = normalize_dataframe_columns(df)
        print(f"üîÑ –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df_normalized.columns)}")
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É gender
        df_normalized = fix_gender_column(df_normalized)
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        for col in EXPECTED_FEATURES:
            if col not in df_normalized.columns:
                df_normalized[col] = 0
                print(f"‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col}")
        
        # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
        df_final = df_normalized[EXPECTED_FEATURES]
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        y_proba = model.predict_proba(df_final)[:, 1]
        predictions = (y_proba > threshold).astype(int)

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ ID - Prediction
        results = []
        for i, (id_val, prediction, probability) in enumerate(zip(ids, predictions, y_proba)):
            results.append({
                "id": convert_numpy_types(id_val),
                "prediction": convert_numpy_types(prediction),
                "probability": convert_numpy_types(probability),
                "risk_category": "high_risk" if prediction == 1 else "low_risk"
            })

        response_data = {
            "filename": file.filename,
            "records_count": len(df),
            "results": results,
            "summary": {
                "high_risk_count": convert_numpy_types(sum(predictions)),
                "low_risk_count": convert_numpy_types(len(predictions) - sum(predictions)),
                "high_risk_percentage": f"{(sum(predictions) / len(predictions) * 100):.1f}%"
            }
        }
        
        return convert_numpy_types(response_data)
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")

@app.post("/predict_single/")
async def predict_single(data: dict):
    try:
        if model is None:
            raise HTTPException(status_code=500, detail="–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame
        df = pd.DataFrame([data])
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –µ—Å–ª–∏ –µ—Å—Ç—å
        record_id = data.get('id', 1)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
        df_normalized = normalize_dataframe_columns(df)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É gender
        df_normalized = fix_gender_column(df_normalized)
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        for col in EXPECTED_FEATURES:
            if col not in df_normalized.columns:
                df_normalized[col] = 0
        
        # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
        df_final = df_normalized[EXPECTED_FEATURES]
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        y_proba = model.predict_proba(df_final)[:, 1][0]
        prediction = int(y_proba > threshold)
        
        response_data = {
            "id": convert_numpy_types(record_id),
            "prediction": convert_numpy_types(prediction),
            "probability": convert_numpy_types(y_proba),
            "risk_category": "high_risk" if prediction == 1 else "low_risk"
        }
        
        return convert_numpy_types(response_data)
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)